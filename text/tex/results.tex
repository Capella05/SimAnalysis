\section{A lens modeling challenge} \label{sec:mod_challenge}

% \subsection{\sw} \label{sec:SpaceWarps} some words about \sw

Interested volunteers from the \sw forum were initially introduced to
\spl through a video tutorial and by videocon.  After this
introductory stage, a modeling challenge was presented.  This
consisted of 29 simulated lenses (sims) covering a range of lensing
configurations.

The \sw sims were generated by AM, in consultation with PM and AV.
To estimate the performance of the volunteers and the quality of the generated models, two analyses  were done.
The first tested the correct identification and ordering of lensed images.
The second compared the mass distribution of the lens $\kappa(x, y)$ of the generated models to the mass distribution of the simulations.


\subsection{The simulated lenses} \label{sec:sims}

In the interest of blind testing, the information in this section was
revealed neither to RK, while choosing the challenge set of 29 sims,
nor to the modellers (volunteers EB, CC, CM, JO, JW and `expert
modeller' PS) until the modelling stage was done.

The sims were produced using {\tt gravlens}
\citep{2001astro.ph..2341K,2001astro.ph..2340K}.  There were of three
kinds, as follows.

\begin{enumerate}
  \item Imitating lensed quasars: having a singular elliptical
    isothermal lens (SIE) plus constant external shear, and a circular
    Gaussian source.
  \item Emulating lensed galaxies: similar to the above, but with an
    elliptical de Vaucouleurs source.
  \item Resembling cluster lenses: having a source as above, but a
    more complicated lens, with one dominant elliptical SIE and
    one or more perturbing elliptical SIEs, plus a circular NFW
    \citep{1996ApJ...462..563N,1997ApJ...490..493N} to represent
    the intergalactic mass.
\end{enumerate}

Formulas for the lenses appear in \cite{2001astro.ph..2341K}. The SIE
lenses follow equations (33--35) of that work, with core radius set to
zero.  The NFW lens is in equations (48) and (50), while shear is the
$\gamma$ term in equation (76).

\subsection{Some example models} \label{sec:example_models}

The modellers proffered a total of 129 models for the 29 sims in the
challenge.  Figures \ref{fig:6941} to \ref{fig:6919} show eight of
models in some detail.

Figure \ref{fig:6941} shows a simple example.  The top two panels show
contours of convergence $\kappa(x,y)$, and of the arrival-time for a
point source at the brightest point of the sim
source.\footnote{Although the arrival-time contours represent an
  abstract quantity that is not directly observable, the contour map
  may actually resemble the appearance of the lensed arcs.  The
  resemblance is due to a serendipitous computer-graphical effect
  \citep{2001AJ....122..585S}.} The spatial scale is in pixels.  The
information in these two panels was, of course, kept secret during the
modelling challenge.  The panels in the middle row and at the lower
right are the results that \spl returns to the modeller, in order for
them to assess the model.  These derive from the mean of an ensemble
of 200 models generated by \spl.  The model mass distribution (left mid) is
returned as a contour map superimposed on an intensity map. A fairly
smooth mass distribution, as here, is a good sign.  An irregular or
checkboard pattern in the mass map usually indicates a bad model.  The
models arrival-time contours are shown in the right middle panel.
  The special contour passing through a
saddle point is shown in black: this is the model version of the
spaghetti sketch provided by the user.  Also provided is a synthetic
image of the lensed source in the bottom right panel.
  For this, \spl assumes a simple conical
source profile.  The user can change the contrast level on the image,
which (though it is not saved) amounts to adjusting the width of
the cone.  Finally, to the lower left of the figure, we have a
comparison of the input and recovered mass profiles.  The panel shows
a average $\kappa$ within a given radius, as a function of radius.
The red curve is the true value, and where it crosses unity (dotted
horizonal line) is the notional Einstein radius $\Theta_{\text{E, sim}}$.
  The two blue curves
are the minimal and maximal mean enclosed $\kappa$ from the internal
ensemble in \spl.  The region between the blue curves is shaded
between the radii of the innermost and the outermost images --- this
is the confidence region from the modelling.  As we see, the shaded
blue is slightly above the red curve. 
The Einstein Radius $\Theta_\text{E}$ of the model is estimated crossing the
mean enclosed $\kappa$ (not plotted) with unity.
  In summary: the identification
of minimum and saddle point is correct, but the estimated Einstein
radius is a little too high.

Figure \ref{fig:6975} shows a lens with substructure in the form of a
smaller secondary galaxy.  The galaxies in such group or cluster sims
were, in fact, based on galaxies visible in the images --- but the
modellers were not told in advance whether this was the case.  The
model does not include any substructure, but otherwise is not bad.
The minimum and saddle point are correct, and the Einstein radius is
only a little underestimated.

Figure \ref{fig:6937} shows a case where substructure leads to a
poor model.

Figure \ref{fig:6990} shows an example of an arc that has split into
three images.  This kind of configuration, with a counter-image close
to the lensing galaxy and a more distant arc/triplet on the other
side, generically arises from an elongated mass distribution when the
source is displaced along the elongated direction.

Figure \ref{fig:6915} shows another quad.  This kind of configuration
arises when the mass is elongated and the source is displaced at an
angle to the elongation.

Figure \ref{fig:6975} shows a fairly symmetric quad.  The minima and
saddle points are correctly identified, and the orientation of the
ellipticity of the mass distribution is correctly reproduced.  The
Einstein radius is somewhat overestimated.  Figure \ref{fig:7022}
shows another model of the same system.  In this one, the
identification of the minima and saddle points was incorrect, and mass
distribution comes out elongated East-West instead of North-South.
The mass distribution also appears somewhat jagged and the
saddle-point contours are not as clean as in the previous examples;
these are often indicators of a problem with the model.  The enclosed
mass is, however, none the worse --- the reason is probably that in a
relatively symmetric image configuration, the Einstein radius is quite
well constrained by the images in a fairly model-independent way.

To conclude this set of examples, Figure \ref{fig:6919} shows another
type of quad.  Actually, in this case the brightest part of the source
is only doubly imaged, but the source extends into a region that
produces four images.  We can also see from the real arrival-time
surface that a point source is a double on the verge of splitting into
a quad.  The modeller interpreted the system as a quad.  The
appearance of the arcs, shown in the bottom panel of Figure
\ref{fig:input-spag}, looks like an arc and counter-image such as
discussed with Figure \ref{fig:6990} above.  But there is an important
difference: the long arc is closer to the galaxy, as if the arc and
counter-image have swapped roles.  This configuration arises if the
source displacement is perpendicular to the long axis of the lensing
mass.

\subsection{Test of image identification} \label{sec:tests.t1}

A first manual evaluation tested the volunteers ability to reconstruct the arrival time surface given a survey image containing a sim.
This task consists of two parts.
First to correctly identify and locate the lensed images.
Second the correct ordering for the identified lensed images in respect of the arrival time.

While we expected the identification of lensed images to be trivial, given the nature of the survey images and the success of \sw, we expect the correct ordering to be more difficult.
This tests the volunteers understandings of the theory of arrival time surfaces and the odd number theorem.
While we can provide the volunteers with some general rules of thumb, ordering involves imagination and guessing and therefore training could improve results in a later stage.

This first test was designed to give some feedback on the difficulties volunteers encounter, to further improve the tutorial materials.

The evaluation of the volunteers performance was done manually, comparing their input from \spl and the resulting reconstructed arrival time surface contour line plot (arrival plot) to the arrival plot generated using simulation parameters.
% \Figref{output_compare} shows the setup used to evaluate the models.

The images of the system are considered to be identified correcly, if all the images have been identified and are approx. within $\pm0.05\cdot\text{imgage width}$.
The parity is considered correct, if those identified points have the right ordering with respect to arrival time.

Additionally, ten types of errors (labeled E01 -- E10, listed in \tabref{stats}) that occurred were identified.
Each generated model could contain more than one error.

% The complete table with the results for each model can be found in
% the appendix, \tabref{detail_results}.

%\begin{enumerate}
%1  \item inaccurate placement in an extended arc
%2  \item wrongly identified sad and min in 3 image configuration
%3  \item identified only 3 instead of 5 images
%4  \item tried to model an arc with a min instead of min-sad-min
%5  \item PI-err (rotation by 180 degrees; in 5 image configuration, exchanged the ordering of the two saddle points)
%6  \item PI/2-err (rotation by 90 degree; sad$\longmapsto$min$\longmapsto$sad$\longmapsto$min$\longmapsto$sad)
%7  \item missed faint image(s)
%8  \item tried to model an arc with min-sad-min instead of only min
%9  \item did identify two close by images as one
%10  \item used 7 or more image to model a 5 image system.
%\end{enumerate}


\tabref{stats} presents a summary of this evaluation.
We conclude that the volunteers are performing very well identifying and positioning images, with a performance of 92\% (R1, p=0.92).
Most of the problems where due to unclear arc-like structures (E01, p=0.18; E04, p=0.03; E08, p=0.04).
Critical errors like the failure to identify all five images in a five images system (E03, p=0.04) or to include too many images (E10, p=0.01) did almost never happen.
From this we conclude that the introduction materials was adequate and the volunteers understand the basics of gravitational lensing.

The assignment of the parity of the images was a more difficult task.
In 59\% (R2, p=0.59, N=70) of the cases the volunteers succeeded to identify the right configuration.
Most of the failures are due to E06 (N=38, p=32\%), followed by E05 (N=7, p=6\%).
E06 describes a situation, where the minima and saddle points of a five image configuration were exchanged (rotated by $\pm90\dgr$), see \figref{7022} for an example.
E05 describes a situation, where the ordering of the saddle points was wrong (rotation by $180\dgr$).
While these errors occurred, we suspect they can be avoided with better training material and some examples for the obvious cases.
For more challenging cases, like very symmetrical distribution of the lensed images (for example model 7022, \figref{7022}), those errors should still produce plausible results, as will be explained in the next section.



\subsection{Test of mass-profile recovery} \label{sec:tests.t2}

The second test was to compare the mass distribution of the lens $\kappa(x, y)$ of the models and the sims.
To get a means of comparing the sims to the models, the total convergence, also called enclosed mass $\kappa_{\text{encl}}(r)$ was calculated for both.
The Einstein radius $\Theta_E$ is defined by $\kappa_{\text{encl}}(\Theta_E)=1$ and gives a number that allows the comparison between a sim and a model.
We also let an expert (PS) model three selected systems to compare the results from volunteers to those of a professional.


To compare the enclosed mass profile and the Einstein radius of the simulation and the models, \kenc was calculated using the mass map \kap[x,y] generated in the modeling process.
From the ensemble of models generated by one modeling process, the mean is taken as the resulting $\kappa(r)$ to calculate $\theta_E$.
To estimate the errors, also the extremal models are used to estimate a lower and upper limit for $\theta_E$.
These results can be seen in \figref{ER_all_models}.
This figure shows that this technique of estimating the error minimizes the error significantly and should be improved for further analysis.


In \figref{ER_per_sim} can be seen, that the calculated \ERf of the models tend to be too high.
The overshoot varies from around 0.2 to 0.4 for good models.
One of the reasons for this is, that it's hard to get the center of the lens on spot.
An offset leads to a flatter mass profile for the model compared to the simulation.





E05 and E06 happen mostly in very symmetric images, that are hard to come up with a unique valid solution.
This errors change the orientation of the mass distribution \kap[x,y],
but \kenc and thus the \ERf is not influenced that much, and thus the final result is still a valid model.
This can be seen by comparing the results for \asw{0h2m}, shown in \figref{kapenc_compare_faulty}: 
The correct model 7022 ($\ERm=10.76px$), which was done by an expert, and
7020 ($\ERm=10.72px$),
7024 ($\ERm=10.80px$),
7025 ($\ERm=11.16px$),
7021 ($\ERm=11.04px$).
The first three are of type E06, while the last is of type E05.
This can be easily corrected, if further analysis is done for the modeled system and time delays are known.


Comparing the models from volunteers and experts can be done in \figref{kapenc_compare_faulty}, where only the
expert got the right configuration, but all the resulting models are comparable, besides rotation.

Two additional sims were modeled by an expert, \asw{1hpf} and \asw{0vqg}.
Looking at the results for \ERg for those models in \figref{ER_per_sim}, we conclude that the performance of volunteers (blue crosses) and experts (red crosses, offset) is comparable.
Note that the models of \asw{0vqg} with \ERg[, rel] around 0.25 (6935 -- 6937) are failed models that show the attempts of a single user, that came finally up with model 6938 as final result.\todo{remove?}

\clearpage
